## math
1. [为什么KL-divergence 可以用来衡量两个概率分布的不相似性？](http://blog.csdn.net/zhaoyawei09/article/details/52434405)
2. [K-L散度（相对熵）总结](http://blog.csdn.net/code_caq/article/details/71150855)
3. [如何理解KL散度的不对称性](https://www.jiqizhixin.com/articles/0224)
4. [初学机器学习：直观解读KL散度的数学概念](https://www.jiqizhixin.com/articles/2018-05-29-2)
5. [从七桥问题开始：全面介绍图论及其应用](https://www.jiqizhixin.com/articles/2018-03-11-2)
6. [从信息论的角度理解与可视化神经网络](https://www.jiqizhixin.com/articles/2018-04-11-2)
7. [贝叶斯线性回归方法的解释和优点](https://www.jiqizhixin.com/articles/2018-04-25-3)
8. [一起读懂传说中的经典：受限玻尔兹曼机](https://www.jiqizhixin.com/articles/2018-05-07-7)
9. [【原】关于使用sklearn进行数据预处理 —— 归一化/标准化/正则化](https://www.cnblogs.com/chaosimple/p/4153167.html)
10. [正则化与模型选择](https://www.jiqizhixin.com/articles/2019-01-25-2)


## Neural Networks
1. [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/neural-networks-3/)
2. [专访MIT教授Tomaso Poggio：表达、优化与泛化——数学视角里的深度学习](https://www.jiqizhixin.com/articles/tomaso-poggio)
3. [DeepMind提出神经元删除法：通过理解每个神经元来理解深度学习](https://www.jiqizhixin.com/articles/032302)
4. [可视化LSTM网络：探索「记忆」的形成](https://www.jiqizhixin.com/articles/2018-03-31-2)
5. [一文简述ResNet及其多种变体](https://www.jiqizhixin.com/articles/042201)
6. [神经语言模型如何利用上下文信息：长距离上下文的词序并不重要](https://www.jiqizhixin.com/articles/2018-06-04-16)
7. [Attention模型方法综述 | 多篇经典论文解读](https://www.jiqizhixin.com/articles/2018-06-11-16)
8. [NLP领域的ImageNet时代到来：词嵌入「已死」，语言模型当立](https://www.jiqizhixin.com/articles/2018-07-09-9)
9. [重新发现语义分割，一文简述全卷积网络](https://www.jiqizhixin.com/articles/071902)


## loss
1. [机器学习大牛最常用的5个回归损失函数，你知道几个？](https://www.jiqizhixin.com/articles/2018-06-21-3)
2. [损失函数——Hinge](https://zhuanlan.zhihu.com/p/35708936)
3. [一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉](https://blog.csdn.net/tsyccnh/article/details/79163834)

## 激活函数
1. [一文概览深度学习中的激活函数](https://www.jiqizhixin.com/articles/2017-11-02-26)
2. [26种神经网络激活函数可视化](https://www.jiqizhixin.com/articles/2017-10-10-3)
3. [谷歌大脑提出新型激活函数Swish惹争议：可直接替换并优于ReLU？（附机器之心测试）](https://www.jiqizhixin.com/articles/2017-10-21-4)


## strategies for optimizing SGD
1. [Active Learning: 一个降低深度学习时间，空间，经济成本的解决方案](https://www.jiqizhixin.com/articles/2017-09-21-12)
2. [一文概览深度学习中的五大正则化方法和七大优化策略](https://www.jiqizhixin.com/articles/2017-12-20)
3. [机器学习系统性能不尽人意？吴恩达教你如何选择改进策略](https://www.jiqizhixin.com/articles/2017-12-25-8)
4. [十倍模型计算时间仅增20%：OpenAI开源梯度替换插件](https://www.jiqizhixin.com/articles/2018-01-16-5)
5. [SGD过程中的噪声如何帮助避免局部极小值和鞍点？](https://www.jiqizhixin.com/articles/051303)
6. [【梯度下降法】二：冲量（momentum）的原理与Python实现](http://www.jianshu.com/p/58b3fe300ecb)
7. [路遥知马力——Momentum](https://zhuanlan.zhihu.com/p/21486826)
8. [比Momentum更快：揭开Nesterov Accelerated Gradient的真面目](http://dudu.zhihu.com/story/8868047)


## embedding
1. [词嵌入2017年进展全面梳理：趋势和未来方向](https://www.jiqizhixin.com/articles/2017-10-25-2)
2. [如何用深度学习处理结构化数据？](https://www.jiqizhixin.com/articles/2017-12-04-7)
3. [当前最好的词句嵌入技术概览：从无监督学习到监督、多任务学习](https://www.jiqizhixin.com/articles/2018-06-06-4)
4. [fastText，智慧与美貌并重的文本分类及向量化工具](https://www.jiqizhixin.com/articles/2018-06-05-3)


## 推荐系统
1. [36氪首发 | 今日头条推荐算法原理全文详解](http://36kr.com/p/5114077.html)
2. [Netflix个人化推荐系统，让每个用戶看到不一样的电影海报](https://www.jiqizhixin.com/articles/2018-03-12-8)
3. [机器学习模型的衡量不止准确率，还有精度和召回率](https://www.jiqizhixin.com/articles/2018-03-17-5)


## 主题模型
1. [一文读懂如何用LSA、PSLA、LDA和lda2vec进行主题建模](https://www.jiqizhixin.com/articles/topic-modeling-with-lsa-psla-lda-and-lda2vec)


## 分词
1. [分词，新词发现和热词发现](http://blog.csdn.net/smartcat2010/article/details/77883735)
2. [有哪些比较好的新词发现方案？](https://www.zhihu.com/question/19650548)


## retrieve
1. [如何在Python中快速进行语料库搜索：近似最近邻算法](https://www.jiqizhixin.com/articles/2018-01-24-3)


## classification
1. [就喜欢看综述论文：情感分析中的深度学习](https://www.jiqizhixin.com/articles/Deep-Learning-for-Sentiment-Analysis)
2. [文本情感分析：让机器读懂人类情感](https://www.jiqizhixin.com/articles/2016-07-02)
3. [How to improve classification of small texts](https://stackoverflow.com/questions/34513634/how-to-improve-classification-of-small-texts)
4. [How to handle Imbalanced Classification Problems in machine learning?](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)
5. [中文文本分类：你需要了解的10项关键内容](https://www.jiqizhixin.com/articles/2018-10-29-10)


## chatbot
1. [微信智言夺冠全球对话系统挑战赛，冠军解决方案全解析](https://www.jiqizhixin.com/articles/2019-03-20-14)
2. [思必驰推出启发式对话系统，关注知识传播的会话精灵](https://www.jiqizhixin.com/articles/2018-07-20-4)


## 调参
1. [深度学习调参有哪些技巧？](https://www.zhihu.com/question/25097993/answer/153674495)
2. [ICML 2017最佳论文：为什么你改了一个参数，模型预测率突然提高了|分享总结](https://www.leiphone.com/news/201708/Hbjv7EcuXTYQlLk2.html)
3. [理解深度学习中的学习率及多种选择策略](https://www.jiqizhixin.com/articles/understanding-learning-rates)
4. [1cycle策略：实践中的学习率设定应该是先增再降](https://www.jiqizhixin.com/articles/041905)


## python
1. [Cython三分钟入门](https://blog.csdn.net/gzlaiyonghao/article/details/4561611)
2. [Python进阶：切片的误区与高级用法](https://www.jiqizhixin.com/articles/2018-12-29-20)
3. [没有什么内存问题，是一行Python代码解决不了的](https://www.jiqizhixin.com/articles/2018-12-17-18)


## paper
1. [可视化CapsNet，详解Hinton等人提出的胶囊概念与原理](https://www.jiqizhixin.com/articles/2018-04-07-3)
2. [RNN和LSTM层面的注意力模型](https://www.jiqizhixin.com/articles/2018-05-03-8)[论文](http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)
3. [DeepMind等机构提出「图网络」：面向关系推理](https://www.jiqizhixin.com/articles/061405)
4. [沈向洋等人论文详解微软小冰，公开研发细节](https://www.jiqizhixin.com/articles/2018-12-30-5)


## news
1. [打响新年第一炮，Gary Marcus提出对深度学习的系统性批判](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650735630&idx=1&sn=5840c3e9bed487da3a9080d482fcc58e&scene=21#wechat_redirect)
2. [「我是可微分编程的粉丝」，Gary Marcus再回应深度学习批判言论](https://www.jiqizhixin.com/articles/2018-01-15-4)
3. [微软披露小冰背后的基础框架与核心技术](https://www.jiqizhixin.com/articles/full-duplex-voice-sense)


## tools
1. [教程 | 如何在TensorFlow中高效使用数据集](https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9748800803704015829%22%7D&n_type=1&p_from=3)
2. [5种快速易用的Python Matplotlib数据可视化方法](https://www.jiqizhixin.com/articles/031310)
3. [如何在TensorFlow中高效使用数据集](https://www.jiqizhixin.com/articles/03137)
4. [用 Sacred 追蹤實驗數據](http://city.shaform.com/blog/2017/03/18/run-experiments-with-sacred.html)
5. [tensorflow学习笔记（二十五）：ConfigProto&GPU](https://blog.csdn.net/u012436149/article/details/53837651)
6. [算法太多挑花眼？此文教你如何选择正确的机器学习算法](https://www.jiqizhixin.com/articles/choosing-the-right-machine-learning-algorithm)
7. [令人困惑的TensorFlow！](https://www.jiqizhixin.com/articles/2018-07-02-6)
8. [Python数据分析之numpy](https://www.jiqizhixin.com/articles/2018-07-18-2)
9. [为什么Python这么慢？](https://www.jiqizhixin.com/articles/2018-08-14-11)
10. [自然语言处理是如何工作的？一步步教你构建 NLP 流水线](https://www.jiqizhixin.com/articles/081203)
11. [正则表达式的功法大全，做NLP再也不怕搞不定字符串了](https://www.jiqizhixin.com/articles/2018-10-09-13)


## data
1. [从文本处理到自动驾驶：机器学习最常用的50大免费数据集](https://www.jiqizhixin.com/articles/the-50-best-free-datasets-for-machine-learning)


## 其它
1. [学习如何学习的算法：简述元学习研究方向现状](https://www.jiqizhixin.com/articles/2018-04-05-2)
2. [机器学习时代的哈希算法，将如何更高效地索引数据](https://www.jiqizhixin.com/articles/2018-05-06-3)
3. [小样本学习年度进展|VALSE2018](https://www.jiqizhixin.com/articles/2018-06-20-13)
4. [如何改善你的训练数据集？（附案例）](https://www.jiqizhixin.com/articles/2018-08-06-6)
5. [基于TextRank算法的文本摘要（附Python代码）](https://www.jiqizhixin.com/articles/2018-12-28-18)
6. [集成学习算法(Ensemble Method)浅析](https://www.jiqizhixin.com/articles/2018-12-28-11)
7. [字符级NLP优劣分析：在某些场景中比词向量更好用](https://www.jiqizhixin.com/articles/19032404)

